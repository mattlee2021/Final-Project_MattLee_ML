{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: Using Academic and Social Factors of High School Students to Predict College Aspirations\n",
    "\n",
    "Description: \n",
    "My project uses classification to determine the primary factors that determine whether or not a student would like to achieve higher education (college). In addition, I built a model that may help education administrators determine whether a given student would like to attend college, and the model illuminates those features that are strong predictors of whether or not a student will attend college. The dataset is pulled from UCI ML repository and has 33 different column data about a given student. There are in total 1044 training examples that come from student performance in a portuguese and math class. There is a combination of categorical and numerical data.\n",
    "\n",
    "Procedure: \n",
    "\n",
    "The dataset used in this analysis actually comes from two separate datasets that have the same features. One dataset examines student performance in a math class, and the other dataset examines student performance in a portuguese langauge class. Thus, to create my total dataset, I concatenated the two datasets. I then split the data into training and testing data using a 2/3 training, 1/3 test dataset split. In my dataset, I noticed a significant class imbalance with over 70% of students wanting to attend college, so I balanced the classes for my training dataset. To wrap up the data preparation, I converted my categorical data to numerical data using label and one-hot encoding. \n",
    "\n",
    "The bulk of my project centered around testing a diversity of classifier models to determine the model that would be most accurate in predicting whether a student would like to go to college. When testing each model, I used grid search in order to find the optimal hyperparameters for each given model so that I could compare models based on best performance.\n",
    "\n",
    "Results:\n",
    "\n",
    "Starting with linear classifiers, I tried using perceptron, logistic regression, and support vector machines in order to have a breadth of different linear models. Of these linear classifiers, I found logistic regression was the most accurate at approximately 79% when using the testing data; however, all three classifiers were approximately 78% accurate. \n",
    "\n",
    "After testing linear classifiers, I moved onto k nearest neighbors (KNN) and decision trees. I found that KNN and decision tree were more accurate than linear classifiers for testing data at an average accuracy of 89%. Given that the decision tree model does a strong job of feature selection and given that I have 33 features in my model, I tried using random forests to see if I would see any improvement in testing accuracy. When using random forests, I saw the testing accuracy jump to approximately 95%. From the random forest, the most important features for classification were a student's Final grade/First Period Grades, Study Time, Age, Father's Education, and Number of Absences. Lastly, I used a learning curve on the random forest to evaluate the model performance. Between 600 and 800 training examples, the model accuracy sharply jumps up, and accuracy converges at 95% just before 1000 training examples. Since the validation accuracy curve's end behavior approximately mirrors that of the training accuracy curve (see graph below), we can deduce that the random forest model did a strong job. \n",
    "\n",
    "Conclusion and Future Work:\n",
    "\n",
    "From this exercise, I learned that using ensemble classifying methods were more robust than linear classifiers. In particular, random forests outperformed in testing accuracy all other models that I tried. However, random forests can be hard to interpret. I am assuming that having many different decision trees and aspects of majority voting helped to predict the correct class more frequently, but the reasons for this model's particularly strong performance are not clear. During my project, the random forest classifier determined that Final grade/First Period Grades, Study Time, Age, Father's Education, and Number of Absences were the top five most important features that predicted student performance. Perhaps teachers/educators can focus their attention on students that have low performance in these areas so that those students may be more inclined to go to college near the end of high school. \n",
    "\n",
    "In the future, one can perform regression on this same dataset. Perhaps, one can evaluate the degree to which Final Grade/First Period Grades, Study Time, Age, Father's Education, and Number of Absences correlate with a student planning to attend higher educaton. I wonder too whether decision tree regression or random forest regression would outperform linear regression. If so, perhaps there is an underlying connection between ensemble learning models for this particular data. I wonder too whether it is generally true that models with many features — though the mathematical definition of \"many\" should be defined more robustly — generally perform better with decision trees/random forests comapred with linear classifiers that use feature selection, such as l2 regularization. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>reason</th>\n",
       "      <th>guardian</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>schoolsup</th>\n",
       "      <th>famsup</th>\n",
       "      <th>paid</th>\n",
       "      <th>activities</th>\n",
       "      <th>nursery</th>\n",
       "      <th>higher</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>father</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>home</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>home</td>\n",
       "      <td>father</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1039</td>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>R</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>services</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>teacher</td>\n",
       "      <td>services</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1041</td>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1042</td>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>services</td>\n",
       "      <td>services</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1043</td>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>18</td>\n",
       "      <td>R</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>services</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1044 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
       "0        GP   F   18       U     GT3       A     4     4   at_home   teacher   \n",
       "1        GP   F   17       U     GT3       T     1     1   at_home     other   \n",
       "2        GP   F   15       U     LE3       T     1     1   at_home     other   \n",
       "3        GP   F   15       U     GT3       T     4     2    health  services   \n",
       "4        GP   F   16       U     GT3       T     3     3     other     other   \n",
       "...     ...  ..  ...     ...     ...     ...   ...   ...       ...       ...   \n",
       "1039     MS   F   19       R     GT3       T     2     3  services     other   \n",
       "1040     MS   F   18       U     LE3       T     3     1   teacher  services   \n",
       "1041     MS   F   18       U     GT3       T     1     1     other     other   \n",
       "1042     MS   M   17       U     LE3       T     3     1  services  services   \n",
       "1043     MS   M   18       R     LE3       T     3     2  services     other   \n",
       "\n",
       "      reason guardian  traveltime  studytime  failures schoolsup famsup paid  \\\n",
       "0     course   mother           2          2         0       yes     no   no   \n",
       "1     course   father           1          2         0        no    yes   no   \n",
       "2      other   mother           1          2         3       yes     no  yes   \n",
       "3       home   mother           1          3         0        no    yes  yes   \n",
       "4       home   father           1          2         0        no    yes  yes   \n",
       "...      ...      ...         ...        ...       ...       ...    ...  ...   \n",
       "1039  course   mother           1          3         1        no     no   no   \n",
       "1040  course   mother           1          2         0        no    yes   no   \n",
       "1041  course   mother           2          2         0        no     no   no   \n",
       "1042  course   mother           2          1         0        no     no   no   \n",
       "1043  course   mother           3          1         0        no     no   no   \n",
       "\n",
       "     activities nursery higher internet romantic  famrel  freetime  goout  \\\n",
       "0            no     yes    yes       no       no       4         3      4   \n",
       "1            no      no    yes      yes       no       5         3      3   \n",
       "2            no     yes    yes      yes       no       4         3      2   \n",
       "3           yes     yes    yes      yes      yes       3         2      2   \n",
       "4            no     yes    yes       no       no       4         3      2   \n",
       "...         ...     ...    ...      ...      ...     ...       ...    ...   \n",
       "1039        yes      no    yes      yes       no       5         4      2   \n",
       "1040         no     yes    yes      yes       no       4         3      4   \n",
       "1041        yes     yes    yes       no       no       1         1      1   \n",
       "1042         no      no    yes      yes       no       2         4      5   \n",
       "1043         no      no    yes      yes       no       4         4      1   \n",
       "\n",
       "      Dalc  Walc  health  absences  G1  G2  G3  \n",
       "0        1     1       3         6   5   6   6  \n",
       "1        1     1       3         4   5   5   6  \n",
       "2        2     3       3        10   7   8  10  \n",
       "3        1     1       5         2  15  14  15  \n",
       "4        1     2       5         4   6  10  10  \n",
       "...    ...   ...     ...       ...  ..  ..  ..  \n",
       "1039     1     2       5         4  10  11  10  \n",
       "1040     1     1       1         4  15  15  16  \n",
       "1041     1     1       5         6  11  12   9  \n",
       "1042     3     4       2         6  10  10  10  \n",
       "1043     3     4       5         4  10  11  11  \n",
       "\n",
       "[1044 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_math=pd.read_csv(\"student-mat.csv\", sep=\";\")\n",
    "data_por=pd.read_csv(\"student-por.csv\", sep=\";\")\n",
    "data=pd.concat([data_math,data_por])\n",
    "data=data.reset_index(drop=True)\n",
    "pd.set_option('display.max_columns', None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Splitting Testing and Training Data ##\n",
    "y=data['higher']\n",
    "X=data.loc[:, data.columns!='higher']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Upsampling training ## \n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "no_col = train_data.loc[train_data['higher']==\"no\"]\n",
    "yes_col = train_data.loc[train_data['higher']==\"yes\"]\n",
    "no_col_upsampled=resample(no_col, replace=True, n_samples=len(yes_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After resampling...\n",
      "Number in Class Yes to College 639\n",
      "Number in Class No to College 639\n"
     ]
    }
   ],
   "source": [
    "## Concatenating Upsampled Training Data ## \n",
    "train_data=pd.concat([yes_col,no_col_upsampled])\n",
    "print(\"After resampling...\")\n",
    "print(\"Number in Class Yes to College\", (train_data['higher']==\"yes\").sum())\n",
    "print(\"Number in Class No to College\", (train_data['higher']==\"no\").sum())\n",
    "X_train=train_data.loc[:, train_data.columns!='higher']\n",
    "y_train=train_data['higher']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenating Testing Data For Consistency ## \n",
    "test_data = pd.concat([X_test, y_test], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preparing ColumnTransformer That Uses OneHotEncoding To Encode Categorical Variables ## \n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.compose import ColumnTransformer \n",
    "le = LabelEncoder() \n",
    "columnTransformer = ColumnTransformer([('encoder', \n",
    "                                        OneHotEncoder(), \n",
    "                                        [0,1,3,4,5,8,9,10,11,15,16,17,18,19,20,21,22])], \n",
    "                                      remainder='passthrough') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting Training Categorical Variables to Numerical ##\n",
    "# Note, using one hot encoding was recommended by sklearn docs over label encoding for feature columns #\n",
    "X_train = columnTransformer.fit_transform(X_train)\n",
    "y_train = le.fit_transform(y_train) #no=0, yes=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Converting Testing Categorical Variables to Numerical ##\n",
    "# Note, using one hot encoding was recommended by sklearn docs over label encoding for feature columns #\n",
    "X_test = columnTransformer.fit_transform(X_test)\n",
    "y_test = le.fit_transform(y_test) #no=0, yes=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standardizing Data ## \n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train) ## Note that we standard only on the basis of the training set\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "#Reformatting after running test_split\n",
    "X_combined_std = np.vstack((X_train_std, X_test_std))\n",
    "y_combined = np.hstack((y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBelow I test my data on the Perceptron, Logistic Regression, SVM, Decision Trees, KNN, and Random Forest models. \\nIn the doc strings below is the Grid Search Output for best hyperparameters and associated best score.\\nI take the best parameters outputted from the grid search and input those into the model. \\nGenerally, I used a log scale for linear classifiers to try different grid search values for maximal breadth \\nbut minimal runtime associated with grid search. For decision trees, KNN, and random trees, I used a breadth of \\nhyperparamter values that were near what we did in class and that were suggested in sklearn docs.\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Below I test my data on the Perceptron, Logistic Regression, SVM, Decision Trees, KNN, and Random Forest models. \n",
    "In the doc strings below is the Grid Search Output for best hyperparameters and associated best score.\n",
    "I take the best parameters outputted from the grid search and input those into the model. \n",
    "Generally, I used a log scale for linear classifiers to try different grid search values for maximal breadth \n",
    "but minimal runtime associated with grid search. For decision trees, KNN, and random trees, I used a breadth of \n",
    "hyperparamter values that were near what we did in class and that were suggested in sklearn docs.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "perceptron_GS = [{'alpha': [.0001,.001,.01,.1], 'eta0': [.01, .1, 1, 10, 100]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified test set examples: 76\n",
      "Out of a total of: 345\n",
      "Accuracy: 0.7797101449275362\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "\"\"\"ppn_gs = GridSearchCV(Perceptron(penalty='l2'), param_grid=perceptron_GS, scoring='accuracy', cv=10, refit=True)\n",
    "ppn_gs_print=ppn_gs.fit(X_train_std, y_train)\n",
    "print(ppn_gs_print.best_score_)\n",
    "print(ppn_gs_print.best_params_)\n",
    "\"\"\"\n",
    "ppn = Perceptron(penalty='l2',eta0=0.1, alpha=.0001, random_state=1)\n",
    "ppn.fit(X_train_std, y_train)\n",
    "ppn_y_pred=ppn.predict(X_test_std)\n",
    "print('Misclassified test set examples:', (y_test != ppn_y_pred).sum())\n",
    "print('Out of a total of:', y_test.shape[0])\n",
    "print('Accuracy:', ppn.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_GS = [{'C': [0.01,0.1,1,10,100,1000], 'solver':['lbfgs', 'newton-cg', 'sag'], 'max_iter':[1000,2500,5000]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified test set examples: 69\n",
      "Out of a total of: 345\n",
      "Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\"\"\"lr_gs = GridSearchCV(LogisticRegression(random_state=1), param_grid=lr_GS, scoring='accuracy', cv=10)\n",
    "lr_gs_print=lr_gs.fit(X_train_std, y_train)\n",
    "print(lr_gs_print.best_score_)\n",
    "print(lr_gs_print.best_params_)\"\"\"\n",
    "\n",
    "lr = LogisticRegression(penalty='l2',C=0.01, max_iter=1000, random_state=1, solver='lbfgs')\n",
    "lr_fitted=lr.fit(X_train_std, y_train)\n",
    "lr_y_pred = lr.predict(X_test_std)\n",
    "print('Misclassified test set examples:', (y_test != lr_y_pred).sum())\n",
    "print('Out of a total of:', y_test.shape[0])\n",
    "print('Accuracy:', lr.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_GS = [{'C': [0.1,1,5,10]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified test set examples: 70\n",
      "Out of a total of: 345\n",
      "Accuracy: 0.7971014492753623\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\"\"\"svm_gs = GridSearchCV(LinearSVC(random_state=1, penalty='l2', max_iter=10000), param_grid=svm_GS, scoring='accuracy', cv=10)\n",
    "svm_gs_print=svm_gs.fit(X_train_std, y_train)\n",
    "print(svm_gs_print.best_score_)\n",
    "print(svm_gs_print.best_params_)\"\"\"\n",
    "\n",
    "svm = LinearSVC(penalty='l2', random_state=1, C=0.1, max_iter=10000)\n",
    "svm.fit(X_train_std, y_train)\n",
    "svm_y_pred = svm.predict(X_test_std)\n",
    "print('Misclassified test set examples:', (y_test != svm_y_pred).sum())\n",
    "print('Out of a total of:', y_test.shape[0])\n",
    "print('Accuracy:', svm.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dTree_GS = [{'max_depth': [10, 12, 13, 14, 15, 16, 18]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified test set examples: 41\n",
      "Out of a total of: 345\n",
      "Accuracy: 0.881159420289855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\"\"\"dTree_gs = GridSearchCV(DecisionTreeClassifier(criterion='entropy',random_state=0), param_grid=dTree_GS,scoring='accuracy', cv=10)\n",
    "dTree_gs_print=dTree_gs.fit(X_train, y_train)\n",
    "print(dTree_gs_print.best_score_)\n",
    "print(dTree_gs_print.best_params_)\"\"\"\n",
    "\n",
    "dTree=DecisionTreeClassifier(max_depth=14,criterion='entropy',random_state=0)\n",
    "dTree.fit(X_train, y_train)\n",
    "dTree_y_pred=dTree.predict(X_test)\n",
    "print('Misclassified test set examples:', (y_test != dTree_y_pred).sum())\n",
    "print('Out of a total of:', y_test.shape[0])\n",
    "print('Accuracy:', dTree.score(X_test, y_test))\n",
    "#print('Importance:', dTree.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN_GS=[{'n_neighbors': [3,5,7,10,13,15]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified test set examples: 28\n",
      "Out of a total of: 345\n",
      "Accuracy: 0.9188405797101449\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "\"\"\"kNN_gs=GridSearchCV(KNeighborsClassifier(metric='minkowski'), param_grid=kNN_GS,scoring='accuracy', cv=10)\n",
    "kNN_gs_print=kNN_gs.fit(X_train_std, y_train)\n",
    "print(kNN_gs_print.best_score_)\n",
    "print(kNN_gs_print.best_params_)\n",
    "\"\"\"\n",
    "\n",
    "kNN=KNeighborsClassifier(n_neighbors=3,metric='minkowski')\n",
    "kNN.fit(X_train_std, y_train)\n",
    "kNN_y_pred=kNN.predict(X_test_std)\n",
    "print('Misclassified test set examples:', (y_test != kNN_y_pred).sum())\n",
    "print('Out of a total of:', y_test.shape[0])\n",
    "print('Accuracy:', kNN.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "randTree_GS = [{'n_estimators': [10, 16, 25, 40, 55, 60, 70, 85, 100, 115, 130]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified test set examples: 29\n",
      "Out of a total of: 345\n",
      "Accuracy: 0.9478260869565217\n",
      "Importance: [0.01462205 0.01605258 0.00867967 0.00815804 0.01302597 0.00960979\n",
      " 0.00797395 0.00946875 0.00598297 0.00474934 0.01846873 0.00539028\n",
      " 0.00845484 0.00658615 0.00303473 0.00549156 0.00122191 0.00892126\n",
      " 0.00834156 0.00246896 0.01150421 0.00618956 0.00720172 0.01137162\n",
      " 0.0046706  0.00826713 0.00687273 0.00743152 0.0080743  0.00608516\n",
      " 0.00758977 0.0103445  0.02066166 0.00608431 0.0102758  0.00629776\n",
      " 0.00605414 0.00468997 0.00849856 0.01154083 0.01398385 0.00474559\n",
      " 0.0014343  0.00700248 0.01058498 0.00832216 0.05266817 0.04432261\n",
      " 0.03078794 0.02567893 0.0587306  0.02573525 0.02757255 0.02429576\n",
      " 0.01817912 0.01524136 0.01867849 0.0249719  0.08519469 0.07179778\n",
      " 0.09366256]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\"\"\"randTree_gs = GridSearchCV(RandomForestClassifier(criterion='entropy',random_state=0), param_grid=randTree_GS,scoring='accuracy', cv=10)\n",
    "randTree_gs_print=randTree_gs.fit(X_train, y_train)\n",
    "print(randTree_gs_print.best_score_)\n",
    "print(randTree_gs_print.best_params_)\"\"\"\n",
    "\n",
    "forest = RandomForestClassifier(criterion='gini',\n",
    "                                n_estimators=55, \n",
    "                                random_state=1,\n",
    "                                n_jobs=2)\n",
    "forest.fit(X_train, y_train)\n",
    "X_combined = np.vstack((X_train, X_test))\n",
    "y_combined = np.hstack((y_train, y_test))\n",
    "forest_y_pred=forest.predict(X_test_std)\n",
    "\n",
    "print('Misclassified test set examples:', (y_test != forest_y_pred).sum())\n",
    "print('Out of a total of:', y_test.shape[0])\n",
    "print('Accuracy:', forest.score(X_test, y_test))\n",
    "print('Importance:', forest.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "train_sizes,train_scores,test_scores = learning_curve(estimator=forest, X=X_train, y=y_train,\n",
    "                                                     train_sizes=np.linspace(0.1,1.0,10), \n",
    "                                                      cv=10)\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, \n",
    "         label='Training accuracy')\n",
    "\n",
    "plt.fill_between(train_sizes,\n",
    "                 train_mean + train_std,\n",
    "                  train_mean - train_std,\n",
    "                  alpha=0.15, color='blue')\n",
    "plt.plot(train_sizes, test_mean,\n",
    "          color='green', linestyle='--',\n",
    "          marker='s', markersize=5,\n",
    "          label='Validation accuracy')\n",
    "plt.fill_between(train_sizes,\n",
    "                  test_mean + test_std,\n",
    "                  test_mean - test_std,\n",
    "                  alpha=0.15, color='green')\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training examples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim([0.8, 1.03])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
